{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Howl06/classify_project_final/blob/main/metric_learning/TripletMarginLossfor_mydateset_change_mobilenetbone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6r2sKa4I9x_",
        "outputId": "deb8628b-4166-46ea-ecb9-d97a203b39c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMde13VLDjiH",
        "outputId": "0da42d75-c06c-4ff8-8a05-d2d01eb01667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-metric-learning\n",
            "  Downloading pytorch_metric_learning-2.1.1-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->pytorch-metric-learning) (16.0.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
            "Installing collected packages: pytorch-metric-learning\n",
            "Successfully installed pytorch-metric-learning-2.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-metric-learning\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/model/deep-learning-for-image-processing-master/data_set/project_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TRH40bvLchA",
        "outputId": "e6413f5d-ff6b-4a06-bfcf-2763d2cd0d7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/model/deep-learning-for-image-processing-master/data_set/project_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqSVqZ5rgfyX",
        "outputId": "4a8f5d92-4acc-40f9-d00d-3d7dd3226ad5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ_L0TrTDnEA",
        "outputId": "e67b90e1-c9b7-48b9-9153-d83971a22339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda:0 device.\n",
            "MobileNetV3(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (16): Conv2dNormActivation(\n",
            "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Linear(in_features=960, out_features=128, bias=True)\n",
            ")\n",
            "Epoch 1 Iteration 0: Loss = 0.08377745002508163, Number of mined triplets = 340\n",
            "Epoch 1 Iteration 20: Loss = 0.07200362533330917, Number of mined triplets = 65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:56<00:00,  3.57s/it]\n",
            "100%|██████████| 21/21 [03:54<00:00, 11.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  x.storage().data_ptr() + x.storage_offset() * 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy (Precision@1) = 0.7884914463452566\n",
            "Epoch 2 Iteration 0: Loss = 0.07317014783620834, Number of mined triplets = 285\n",
            "Epoch 2 Iteration 20: Loss = 0.029953671619296074, Number of mined triplets = 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:44<00:00,  3.43s/it]\n",
            "100%|██████████| 21/21 [01:11<00:00,  3.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.76049766718507\n",
            "Epoch 3 Iteration 0: Loss = 0.051382407546043396, Number of mined triplets = 59\n",
            "Epoch 3 Iteration 20: Loss = 0.09861812740564346, Number of mined triplets = 74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:44<00:00,  3.43s/it]\n",
            "100%|██████████| 21/21 [01:10<00:00,  3.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.7309486780715396\n",
            "Epoch 4 Iteration 0: Loss = 0.07286028563976288, Number of mined triplets = 165\n",
            "Epoch 4 Iteration 20: Loss = 0.058043740689754486, Number of mined triplets = 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:42<00:00,  3.40s/it]\n",
            "100%|██████████| 21/21 [01:11<00:00,  3.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.7993779160186625\n",
            "Epoch 5 Iteration 0: Loss = 0.06582211703062057, Number of mined triplets = 235\n",
            "Epoch 5 Iteration 20: Loss = 0.08257819712162018, Number of mined triplets = 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:40<00:00,  3.38s/it]\n",
            "100%|██████████| 21/21 [01:11<00:00,  3.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.8398133748055987\n",
            "Epoch 6 Iteration 0: Loss = 0.06470416486263275, Number of mined triplets = 91\n",
            "Epoch 6 Iteration 20: Loss = 0.07087907940149307, Number of mined triplets = 108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:41<00:00,  3.39s/it]\n",
            "100%|██████████| 21/21 [01:11<00:00,  3.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.7822706065318819\n",
            "Epoch 7 Iteration 0: Loss = 0.07467734813690186, Number of mined triplets = 227\n",
            "Epoch 7 Iteration 20: Loss = 0.10097064822912216, Number of mined triplets = 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:51<00:00,  3.51s/it]\n",
            "100%|██████████| 21/21 [01:13<00:00,  3.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.744945567651633\n",
            "Epoch 8 Iteration 0: Loss = 0.048790909349918365, Number of mined triplets = 31\n",
            "Epoch 8 Iteration 20: Loss = 0.0808473527431488, Number of mined triplets = 67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:50<00:00,  3.50s/it]\n",
            "100%|██████████| 21/21 [01:13<00:00,  3.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.7807153965785381\n",
            "Epoch 9 Iteration 0: Loss = 0.07908517122268677, Number of mined triplets = 273\n",
            "Epoch 9 Iteration 20: Loss = 0.02100675366818905, Number of mined triplets = 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:35<00:00,  3.32s/it]\n",
            "100%|██████████| 21/21 [01:09<00:00,  3.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.8289269051321928\n",
            "Epoch 10 Iteration 0: Loss = 0.06929855793714523, Number of mined triplets = 38\n",
            "Epoch 10 Iteration 20: Loss = 0.057820722460746765, Number of mined triplets = 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:35<00:00,  3.32s/it]\n",
            "100%|██████████| 21/21 [01:10<00:00,  3.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.8195956454121306\n",
            "Epoch 11 Iteration 0: Loss = 0.06887141615152359, Number of mined triplets = 61\n",
            "Epoch 11 Iteration 20: Loss = 0.08034208416938782, Number of mined triplets = 126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:41<00:00,  3.39s/it]\n",
            "100%|██████████| 21/21 [01:08<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.8833592534992224\n",
            "Epoch 12 Iteration 0: Loss = 0.056162938475608826, Number of mined triplets = 143\n",
            "Epoch 12 Iteration 20: Loss = 0.0, Number of mined triplets = 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [04:35<00:00,  3.32s/it]\n",
            "100%|██████████| 21/21 [01:10<00:00,  3.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.8211508553654744\n",
            "Epoch 13 Iteration 0: Loss = 0.06098878011107445, Number of mined triplets = 46\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision.models import mobilenet_v3_large as mobilenet_v3\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "#         self.dropout1 = nn.Dropout2d(0.25)\n",
        "#         self.dropout2 = nn.Dropout2d(0.5)\n",
        "#         self.gab = nn.AdaptiveAvgPool2d(1)\n",
        "#         self.fc1 = nn.Linear(64, 128)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x) # batchsize 3 224 224  -> batchsize 32 224 224 \n",
        "#         x = F.relu(x)\n",
        "#         x = self.conv2(x) # batchsize 32 224 224  -> batchsize 64 224 224 \n",
        "#         x = F.relu(x)\n",
        "#         x = F.max_pool2d(x, 2) # batchsize 64 224 224 -> batchsize 64 112 112\n",
        "#         x = self.dropout1(x)\n",
        "#         x = self.gab(x)     # batchsize 64 112 112 -> batchsize 64 1\n",
        "#         x = torch.flatten(x, 1) # batchsize 64 1 -> batchsize 64\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        embeddings = model(data)\n",
        "        indices_tuple = mining_func(embeddings, labels)\n",
        "        loss = loss_func(embeddings, labels, indices_tuple)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(\n",
        "                \"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(\n",
        "                    epoch, batch_idx, loss, mining_func.num_triplets\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "### convenient function from pytorch-metric-learning ###\n",
        "def get_all_embeddings(dataset, model):\n",
        "    tester = testers.BaseTester()\n",
        "    return tester.get_all_embeddings(dataset, model)\n",
        "\n",
        "\n",
        "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
        "def test(train_set, test_set, model, accuracy_calculator):\n",
        "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
        "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
        "    train_labels = train_labels.squeeze(1)\n",
        "    test_labels = test_labels.squeeze(1)\n",
        "    print(\"Computing accuracy\")\n",
        "    accuracies = accuracy_calculator.get_accuracy(\n",
        "        test_embeddings, test_labels, train_embeddings, train_labels, False\n",
        "    )\n",
        "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"using {} device.\".format(device))\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(224+32),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5232674, 0.49784118, 0.42335856], [0.24051566, 0.23351395, 0.23727049])]\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 20\n",
        "\n",
        "\n",
        "#　dataset1 = datasets.MNIST(\".\", train=True, download=True, transform=transform)\n",
        "train_dataset = datasets.ImageFolder(root=\"./train/\",\n",
        "                                         transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(root=\"./val/\",\n",
        "                                         transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)\n",
        "model = torch.load(\"/content/drive/MyDrive/metric_learning/ml.pt\")\n",
        "# model = mobilenet_v3(pretrained=True)\n",
        "# num_ftrs = model.classifier[0].in_features\n",
        "# model.classifier = nn.Linear(num_ftrs, 128)\n",
        "print(model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "### pytorch-metric-learning stuff ###\n",
        "distance = distances.CosineSimilarity()\n",
        "reducer = reducers.ThresholdReducer(low=0)\n",
        "loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
        "mining_func = miners.TripletMarginMiner(\n",
        "    margin=0.2, distance=distance, type_of_triplets=\"semihard\"\n",
        ")\n",
        "accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1)\n",
        "### pytorch-metric-learning stuff ###\n",
        "\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)\n",
        "    test(train_dataset, valid_dataset, model, accuracy_calculator)\n",
        "    torch.save(model, \"/content/drive/MyDrive/metric_learning/ml.pt\")\n",
        "# epoch 59"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Ljomdm4ntVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}